{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os, sys, shutil, importlib, glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = (15,7)\n",
    "plt.rcParams[\"savefig.dpi\"] = 600\n",
    "from celloracle import motif_analysis as ma\n",
    "from celloracle.utility import save_as_pickled_object\n",
    "import celloracle as co\n",
    "import subprocess\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c31382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 Sketched cells for Network Analysis  https://github.com/brianhie/geosketch\n",
    "adata=sc.read(\"/path/to/trophoblast.h5ad\")  ## load the subset of trophoblast h5ad\n",
    "from geosketch import gs\n",
    "N = 5000 \n",
    "X_dimred=adata.obsm['X_pca']\n",
    "sketch_index = gs(X_dimred, N, replace=False)\n",
    "X_sketch = X_dimred[sketch_index]\n",
    "adata=adata[adata.obs_names[sketch_index],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5385e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#02.TSS annotation  refer to https://github.com/morris-lab/CellOracle/blob/master/docs/notebooks/01_ATAC-seq_data_processing/option1_scATAC-seq_data_analysis_with_cicero/02_preprocess_peak_data.ipynb\n",
    "wdir=\"/path/to/working/directory/\"\n",
    "os.chdir(wdir)\n",
    "peaks = pd.read_csv(\"/path/to/cicero/trophoblast_all_peaks.csv\", index_col=0) ## load all snATAC peaks called within trophoblasts\n",
    "cicero_connections = pd.read_csv(\"/path/to/cicero_conns.csv\", index_col=0) ##\n",
    "\n",
    "peaks=peaks.iloc[:,0].str.replace(\"-\",\"_\").values\n",
    "ref_genome='hg38'\n",
    "tss_annotated = ma.get_tss_info(peak_str_list=peaks, ref_genome=ref_genome)\n",
    "integrated = ma.integrate_tss_peak_with_cicero(tss_peak=tss_annotated,cicero_connections=cicero_connections)\n",
    "peak = integrated[integrated.coaccess >= 0.8]\n",
    "peak = peak[[\"peak_id\", \"gene_short_name\"]].reset_index(drop=True)\n",
    "peak.to_csv(\"/path/to/processed_peak_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#02 motif_scan\n",
    "def decompose_chrstr(peak_str):\n",
    "    *chr_, start, end = peak_str.split(\"_\")\n",
    "    chr_ = \"_\".join(chr_)\n",
    "    return chr_, start, end\n",
    "\n",
    "from genomepy import Genome\n",
    "\n",
    "def check_peak_format(peaks_df, ref_genome):\n",
    "    df = peaks_df.copy()\n",
    "\n",
    "    n_peaks_before = df.shape[0]\n",
    "\n",
    "    # Decompose peaks and make df\n",
    "    decomposed = [decompose_chrstr(peak_str) for peak_str in df[\"peak_id\"]]\n",
    "    df_decomposed = pd.DataFrame(np.array(decomposed))\n",
    "    df_decomposed.columns = [\"chr\", \"start\", \"end\"]\n",
    "    df_decomposed[\"start\"] = df_decomposed[\"start\"].astype(np.int)\n",
    "    df_decomposed[\"end\"] = df_decomposed[\"end\"].astype(np.int)\n",
    "\n",
    "    # Load genome data\n",
    "    genome_data = Genome(ref_genome)\n",
    "    all_chr_list = list(genome_data.keys())\n",
    "\n",
    "\n",
    "    # DNA length check\n",
    "    lengths = np.abs(df_decomposed[\"end\"] - df_decomposed[\"start\"])\n",
    "\n",
    "\n",
    "    # Filter peaks with invalid chromosome name\n",
    "    n_threshold = 5\n",
    "    df = df[(lengths >= n_threshold) & df_decomposed.chr.isin(all_chr_list)]\n",
    "\n",
    "    # DNA length check\n",
    "    lengths = np.abs(df_decomposed[\"end\"] - df_decomposed[\"start\"])\n",
    "\n",
    "    # Data counting\n",
    "    n_invalid_length = len(lengths[lengths < n_threshold])\n",
    "    n_peaks_invalid_chr = n_peaks_before - df_decomposed.chr.isin(all_chr_list).sum()\n",
    "    n_peaks_after = df.shape[0]\n",
    "\n",
    "    #\n",
    "    print(\"Peaks before filtering: \", n_peaks_before)\n",
    "    print(\"Peaks with invalid chr_name: \", n_peaks_invalid_chr)\n",
    "    print(\"Peaks with invalid length: \", n_invalid_length)\n",
    "    print(\"Peaks after filtering: \", n_peaks_after)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "ref_genome = \"hg38\"\n",
    "genome_installation = ma.is_genome_installed(ref_genome=ref_genome)\n",
    "print(ref_genome, \"installation: \", genome_installation)\n",
    "if not genome_installation:\n",
    "    import genomepy\n",
    "    genomepy.install_genome(ref_genome, \"UCSC\")\n",
    "else:\n",
    "    print(ref_genome, \"is installed.\")\n",
    "\n",
    "peaks = check_peak_format(peaks, ref_genome)\n",
    "#load motifs\n",
    "from gimmemotifs.motif import default_motifs\n",
    "motifs =  default_motifs()\n",
    "\n",
    "tfi = ma.TFinfo(peak_data_frame=peaks, ref_genome=ref_genome)\n",
    "\n",
    "tfi.scan(fpr=0.02,motifs=motifs,verbose=True) #long step\n",
    "tfi.to_hdf5(file_path=\"celloracle.tfinfo\")\n",
    "tfi.reset_filtering()\n",
    "tfi.filter_motifs_by_score(threshold=10)\n",
    "# Do post filtering process. Convert results into several file format.\n",
    "tfi.make_TFinfo_dataframe_and_dictionary(verbose=True)\n",
    "df=tfi.to_dataframe()\n",
    "df.to_parquet(\"base_GRN_dataframe.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 03  Make celloracle object\n",
    "oracle = co.Oracle()\n",
    "oracle.import_anndata_as_normalized_count(adata=adata,cluster_column_name=\"minor_class\",\n",
    "                                          embedding_name=\"X_umap\")\n",
    "oracle.import_TF_data(TF_info_matrix=df)\n",
    "\n",
    "TG_to_TF_dictionary = tfi.to_dictionary(dictionary_type=\"targetgene2TFs\")\n",
    "oracle.addTFinfo_dictionary(TG_to_TF_dictionary)\n",
    "\n",
    "# Perform PCA\n",
    "oracle.perform_PCA()\n",
    "\n",
    "# Select important PCs\n",
    "plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])\n",
    "n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]\n",
    "plt.axvline(n_comps, c=\"k\")\n",
    "plt.show()\n",
    "print(n_comps)\n",
    "n_comps = min(n_comps, 50)\n",
    "n_cell = oracle.adata.shape[0]\n",
    "k = int(0.025*n_cell)\n",
    "oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,b_maxl=k*4, n_jobs=4)\n",
    "oracle.to_hdf5(\"tp.celloracle.oracle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##04 GRN inference\n",
    "links = oracle.get_links(cluster_name_for_GRN_unit=\"minor_class\", alpha=10,\n",
    "                         verbose_level=10)\n",
    "links.to_hdf5(\"links.celloracle.links\")\n",
    "links.filter_links(p=0.05, weight=\"coef_abs\", threshold_number=10000)\n",
    "# Calculate network scores.\n",
    "links.get_network_score()\n",
    "# Save Links object.\n",
    "links.to_hdf5(file_path=\"filtered_links.celloracle.links\")\n",
    "## export the network for cytoscape visualization\n",
    "for i,j in links.links_dict.items():\n",
    "    j.to_csv(os.path.join(\"/path/to/output/\",i+'.tsv'),sep=\"\\t\",index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oracle",
   "language": "python",
   "name": "oracle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
