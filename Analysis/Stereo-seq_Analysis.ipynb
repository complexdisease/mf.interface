{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a4267-6dab-4ec6-8c03-33930e9bd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 01 Data preprocessing & Normalization & Harmonization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import harmonypy \n",
    "import scanpy.external as sce\n",
    "main_path=\"/path/to/workdir/\"\n",
    "saw_output=\"/path/to/saw_output/\"\n",
    "os.chdir(saw_output)\n",
    "samples=os.listdir()\n",
    "\n",
    "data_paths=[i+'/outs/analysis/'+i+'.cellbin_1.0.adjusted.h5ad' for i in samples]\n",
    "\n",
    "for i,j in enumerate(data_path):\n",
    "    tmp=sc.read_h5ad(j)\n",
    "    tmp.obs['slide_id']=samples[i]\n",
    "    tmp.obs['slide']=sample[i]\n",
    "    tmp.var['EnsID']=tmp.var.index\n",
    "    tmp.var.real_gene_name=tmp.var.real_gene_name.astype('str')\n",
    "    tmp.var.index=tmp.var.real_gene_name\n",
    "    tmp.var_names_make_unique(\"-\")\n",
    "    tmp.obs['CID']=tmp.obs.index\n",
    "    adata_list.append(tmp)\n",
    "\n",
    "\n",
    "adata=ad.concat(adata_list,label=\"slide_id\")\n",
    "\n",
    "sc.pl.highest_expr_genes(adata, n_top=20, )\n",
    "sc.pp.filter_cells(adata, min_genes=10)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],multi_panel=True)\n",
    "sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt')\n",
    "sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts')\n",
    "adata.obs.index=adata.obs.index.str.cat(adata.obs.batch,sep=\"-\")\n",
    "\n",
    "adata=adata[(adata.obs.n_genes_by_counts < 10000)& (adata.obs.n_genes_by_counts > 50)&(adata.obs.total_counts > 100)\n",
    "    &(adata.obs.total_counts < 8000) &adata.obs.pct_counts_mt.lt(20), :]\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, batch_key='slide',flavor='seurat_v3_paper',n_top_genes=3000)\n",
    "\n",
    "adata.raw = adata\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "sc.pp.scale(adata,max_value=10)\n",
    "sc.tl.pca(adata, use_highly_variable=True,svd_solver='arpack')\n",
    "sce.pp.harmony_integrate(adata,key='slide')\n",
    "sc.pp.neighbors(adata,use_rep='X_pca_harmony',n_pcs=30)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.louvain(adata,resolution=4.0)\n",
    "sc.pl.umap(adata, color=['slide'], use_raw=True)\n",
    "adata.raw.to_adata().write(\"/path/to/integrated_st.h5ad\")\n",
    "\n",
    "## plotting marker gene expression\n",
    "\n",
    "markers=['TP63','LGR5','HOPX','KISS1','HLA-G','KRT7','LAMA2','COL3A1','ACTA2','DLK1','CD34',\n",
    "         'PECAM1','MMP1','VWF','FOXO1','IGFBP1','PAEP','PAX8','GNLY','CD3E','MRC1']\n",
    "\n",
    "sc.pl.dotplot(adata, markers,categories_order=['VCT','SCT','EVT','FB','PV','fVEC','mVEC','DSC','Epi','immune','HB'],dot_max=0.8,\n",
    "              groupby='subclass',use_raw=True,standard_scale='var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303666cf-48f9-4626-8e6c-fd2cb9629031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 02. Adjusting spatial coordianate\n",
    "import numpy as np\n",
    "offset_x=adata.obs.x.max()\n",
    "offset_y=adata.obs.y.max()\n",
    "samples=adata.obs['slide'].unique()\n",
    "adata.obsm['spatial']=np.asarray(adata.obs[['x','y']])\n",
    "adata.obsm['shift_spatial']=adata.obsm['spatial']\n",
    "ncols=6\n",
    "for i, sample in enumerate(samples):\n",
    "    sample_idx = adata.obs[\"slide\"] == sample\n",
    "    if i<ncols:\n",
    "        adata.obsm[\"shift_spatial\"][sample_idx,0] += i * offset_x\n",
    "    else:\n",
    "        adata.obsm[\"shift_spatial\"][sample_idx,0] += (i-ncols) * offset_x\n",
    "        adata.obsm[\"shift_spatial\"][sample_idx,1] += 1 * offset_y\n",
    "sc.pl.embedding(adata,basis=\"shift_spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87e317-5d78-4568-ab6e-0b49d1b50493",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 03 Cell community analysis\n",
    "\n",
    "\n",
    "import stereo as st\n",
    "from stereo.core.stereo_exp_data import AnnBasedStereoExpData\n",
    "from stereo.algorithm.community_detection import CommunityDetection\n",
    "from stereo.core.ms_data import MSData\n",
    "\n",
    "data=st.io.read_h5ad(\"/path/to/integrated_st.h5ad\")\n",
    "ccd = data.tl.community_detection(\n",
    "            annotation='subclass',\n",
    "            out_path='./community/',\n",
    "            win_sizes='300',\n",
    "            sliding_steps='10',\n",
    "            scatter_thres=0.12,\n",
    "            downsample_rate=80,\n",
    "            cluster_algo='agglomerative',\n",
    "            n_clusters=12,\n",
    "            resolution=0.25,\n",
    "            plotting=3,num_threads=20,\n",
    "            hide_plots=False,\n",
    "            min_count_per_type =0.01)\n",
    "\n",
    "\n",
    "\n",
    "## Plotting cell type compositiona across cell community\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "composition = adata.obs.groupby(['ccd', 'subclass']).size().reset_index(name='count')\n",
    "composition['proportion'] = composition.groupby('ccd')['count'].transform(lambda x: x / x.sum())\n",
    "plt.figure(figsize=(10, 5))\n",
    "composition_pivot = composition.pivot(index=\"ccd\", columns=\"subclass\", values=\"proportion\").fillna(0)\n",
    "composition_pivot.plot(kind=\"bar\", stacked=True, colormap=\"tab20\", figsize=(10, 5))\n",
    "plt.title(\"Cell Composition by Distance (Stacked Bar Chart)\")\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f116c4-ce74-449d-8d6e-10c06c5975eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 04.Celltype co-occurence/neighborhood enrichment\n",
    "import squidpy as sq\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "sq.gr.spatial_neighbors(adata spatial_key='shift_spatial', coord_type=\"generic\",delaunay=False)\n",
    "adata2.obs['subclass']=pd.Categorical(adata2.obs['subclass'])\n",
    "sq.gr.nhood_enrichment(adata, cluster_key=\"subclass\",n_perms=1000)\n",
    "df=pd.DataFrame(adata2.uns['subclass_nhood_enrichment']['count'])\n",
    "df.index=adata.obs.subclass.cat.categories\n",
    "df.columns=adata.obs.subclass.cat.categories\n",
    "df=(df.div(df.sum(1),0)+df.div(df.sum(0),1))/2\n",
    "linkage_matrix = linkage(df, method='ward')\n",
    "sns.clustermap(df, cmap='viridis',col_linkage=linkage_matrix,row_linkage=linkage_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a21e8d-309a-4875-9039-703099fa5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 05 Spatial Distance Analysis\n",
    "\n",
    "## calculate the signed distance to the interface\n",
    "from shapely.ops import nearest_points, LineString\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "def signed_distance_interface(point, line):\n",
    "    nearest_point_on_line=nearest_points(line, point)[0]\n",
    "    distance=point.distance(nearest_point_on_line)\n",
    "    coords = line.coords\n",
    "    sign_distance = 0\n",
    "    seg = None\n",
    "    #normal = None\n",
    "    for i in range(len(coords) - 1):\n",
    "        seg_start, seg_end = Point(coords[i]), Point(coords[i+1])\n",
    "        segment = LineString([seg_start, seg_end])\n",
    "        if point.distance(segment)==distance:\n",
    "            tangent = (seg_end.x - seg_start.x, seg_end.y - seg_start.y)\n",
    "        # Compute normal vector (perpendicular to tangent)\n",
    "            #normal = (tangent[0], tangent[1])\n",
    "            seg = (seg_start, seg_end)\n",
    "    if seg:\n",
    "            #point_vec = (point.x - nearest_point_on_line.x, point.y - nearest_point_on_line.y)\n",
    "        point_vec = (point.x - seg[0].x, point.y - seg[0].y)\n",
    "        cross = tangent[0] * point_vec[1] - tangent[1] * point_vec[0]\n",
    "        #sign = 1 if (point_vec[0] * normal[0] + point_vec[1] * normal[1]) > 0 else -1\n",
    "        sign = 1 if cross >0 else -1\n",
    "        sign_distance = distance * sign\n",
    "\n",
    "    return sign_distance\n",
    "    \n",
    "## signed distance to BV\n",
    "def signed_distance_bv(point, polygons):\n",
    "    if polygons.contains(point).any():\n",
    "        polygon=polygons[polygons.contains(point)]\n",
    "        distance=polygon.geometry.boundary.distance(point).min()*-1\n",
    "    # Compute distance to nearest polygon\n",
    "    else:\n",
    "        distance = polygons.geometry.boundary.distance(point).min()\n",
    "    # If the point is inside any polygon, return negative distance\n",
    "    return distance\n",
    "\n",
    "## compute signed distance on masked sample\n",
    "\n",
    "sc.set_figure_params(dpi=80)\n",
    "ids=os.listdir('/path/to/saw_output/')\n",
    "df=[]\n",
    "for id in ids:\n",
    "    mask_gdf = gpd.read_file(os.path.join(\"/path/to/tissue_mask/\",id+\"_seg.geojson\")) ## load coordinates of sample mask and interface lines.\n",
    "    interface_gdf = gpd.read_file(os.path.join(\"/path/to/tissue_mask/\",id+\"_interface.geojson\"))\n",
    "    adata2=adata[adata.obs.slide.isin([id]),:]\n",
    "    points=[Point(i[0],i[1]) for i in adata2.obs[['x','y']].values]\n",
    "    if mask_gdf.shape[0]==2:\n",
    "        sample_ids=[0,1]\n",
    "    else:\n",
    "        sample_ids=[0]\n",
    "    for sample in sample_ids\n",
    "    ## selecting cells masked by each individual samples\n",
    "        points_df=gpd.GeoDataFrame({'geometry': points})\n",
    "        points_df.index=adata2.obs.index\n",
    "        points_df=gpd.sjoin(points_df,mask_gdf.iloc[[sample]])\n",
    "        adata2=adata2[points_df.index,:]\n",
    "\n",
    "        signed_distances,whichline = [],[]\n",
    "        # iterative on all cells to track the o track the minimum signed distance and corresponding line\n",
    "        for j, point in enumerate(points_df.geometry):\n",
    "            min_signed_distance = None\n",
    "            nearest_line = sample  \n",
    "            s_distance = signed_distance_interface(point, interface_gdf.geometry[sample])\n",
    "            signed_distances.append(s_distance)\n",
    "            whichline.append(nearest_line)\n",
    "        points_df['signed_distance'] = signed_distances\n",
    "        points_df['nearest_line'] = whichline\n",
    "        df.append(points_df)\n",
    "df=pd.concat(df,axis=0)\n",
    "df['celltype']=adata.obs.loc[df.index,'celltype']\n",
    "df['subclass']=adata.obs.loc[df.index,'subclass']\n",
    "df.to_csv(\"signed_distance_interface.tsv\",sep=\"\\t\",index=True)\n",
    "\n",
    "## compute signed distance on masked sample\n",
    "for id in ids:\n",
    "    mask_gdf = gpd.read_file(os.path.join(\"/path/to/tissue_mask/\",id+\"_seg.geojson\")) ## load coordinates of sample mask and bv shapes.\n",
    "    bv_gdf = gpd.read_file(os.path.join(\"/path/to/tissue_mask/\",id+\"_BV.geojson\"))\n",
    "    bv_gdf=bv_gdf.drop(bvs.shape[0]-1)\n",
    "    adata2=adata[adata.obs.slide.isin([id]),:]\n",
    "    points=[Point(i[0],i[1]) for i in adata2.obs[['x','y']].values]\n",
    "    if mask_gdf.shape[0]==2:\n",
    "        sample_ids=[0,1]\n",
    "    else:\n",
    "        sample_ids=[0]\n",
    "    for sample in sample_ids\n",
    "    ## selecting cells masked by each individual samples\n",
    "        points_df=gpd.GeoDataFrame({'geometry': points})\n",
    "        points_df.index=adata2.obs.index\n",
    "        points_df=gpd.sjoin(points_df,mask_gdf.iloc[[sample]])\n",
    "        adata2=adata2[points_df.index,:]\n",
    "        \n",
    "        distances = np.array([signed_distance_bv(pt, bv_gdf) for pt in points])     \n",
    "        points_df['signed_distance_BV']=distances\n",
    "        \n",
    "df=pd.concat(df,axis=0)\n",
    "df['celltype']=adata.obs.loc[df.index,'celltype']\n",
    "df['subclass']=adata.obs.loc[df.index,'subclass']\n",
    "df.to_csv(\"signed_distance_BV.tsv\",sep=\"\\t\",index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb36eec-56f2-459c-b65b-f2f4a8e1ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 06 Composition over distance bins\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#interface\n",
    "bins=[-4000,-2000,-1500,-1000,-500,-250,0,250,500,1000,1500,2000,4000]\n",
    "df_interface['distance_bin'] = pd.cut(df_interface['signed_distance_interface'], bins)\n",
    "composition = df_interface.groupby(['distance_bin', 'subclass']).size().reset_index(name='count')\n",
    "composition['proportion'] = composition.groupby('distance_bin')['count'].transform(lambda x: x / x.sum())\n",
    "plt.figure(figsize=(10, 5))\n",
    "composition_pivot = composition.pivot(index=\"distance_bin\", columns=\"subclass\", values=\"proportion\").fillna(0)\n",
    "composition_pivot.plot(kind=\"bar\", stacked=True, colormap=\"tab20\", figsize=(10, 5))\n",
    "#BV\n",
    "bins=[-1000,-100,0,50,100,150,200,300,500,1000]\n",
    "df_bv['distance_bin'] = pd.cut(df_bv['signed_distance_bv'], bins)\n",
    "composition = df_bv.groupby(['distance_bin', 'subclass']).size().reset_index(name='count')\n",
    "composition['proportion'] = composition.groupby('distance_bin')['count'].transform(lambda x: x / x.sum())\n",
    "plt.figure(figsize=(10, 5))\n",
    "composition_pivot = composition.pivot(index=\"distance_bin\", columns=\"subclass\", values=\"proportion\").fillna(0)\n",
    "composition_pivot.plot(kind=\"bar\", stacked=True, colormap=\"tab20\", figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf712cf-9347-48ce-9853-34addb6fa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##07 EVT Density Analysis\n",
    "\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely.ops import unary_union\n",
    "import geopandas as gpd\n",
    "## centroids of vessels\n",
    "files=[i for i in os.listdir(\"/path/to/geojson_dir/\") if '_BV.geojson' in i]\n",
    "for i in files:\n",
    "    bvs=gpd.read_file(i)\n",
    "    bvs=bvs.drop(bvs.shape[0]-1)\n",
    "    id=i.str.replace(\"_BV.geojson\",\"\")\n",
    "    allpoints=adata.obs.loc[(adata.obs.subclass!='EVT')&(adata.obs.slide==id)&(adata.obs.distance_to_interface.gt(-200)),['x','y']]\n",
    "    random_points=np.asarray(allpoints.sample(n=10)) ## sampling cells in maternal side\n",
    "    cell_coords = np.array(adata.obs.loc[(adata.obs.subclass=='EVT')&(adata.obs.slide==id),['x','y']])\n",
    "    #tree = KDTree(cell_coords)\n",
    "    radius = 50\n",
    "    area,nevts,nevts_ctrl=[],[],[]\n",
    "    for idx,p in enumerate(bvs.geometry):\n",
    "        boundary_points = list(p.exterior.coords)\n",
    "        buffers = [Point(pt).buffer(radius) for pt in boundary_points] ## setting annular regions near the vessel wall\n",
    "        combined_buffer = unary_union(buffers)\n",
    "        annular_region = combined_buffer.difference(p)\n",
    "    \n",
    "# Identify cells within the annular region\n",
    "        cells_in_annulus = []\n",
    "        for coord in cell_coords:\n",
    "            point = Point(coord)\n",
    "            if annular_region.contains(point):\n",
    "                cells_in_annulus.append(coord)\n",
    "        cells_in_annulus = np.array(cells_in_annulus)\n",
    "        print(annular_region.area,cells_in_annulus.shape[0],cells_in_annulus.shape[0]/annular_region.area)\n",
    "        area.append(annular_region.area)\n",
    "        nevts.append(cells_in_annulus.shape[0])\n",
    "    \n",
    "        equivalent_radius = np.sqrt(annular_region.area/ np.pi)\n",
    "        tmp=[]\n",
    "        for i in random_points:\n",
    "            random_center = Point(i[0], i[1])\n",
    "            random_circle = random_center.buffer(equivalent_radius)\n",
    "            cells_in_random_area = []\n",
    "            for coord in cell_coords:\n",
    "                point = Point(coord)\n",
    "                if random_circle.contains(point):\n",
    "                    cells_in_random_area.append(coord)\n",
    "            tmp.append(len(cells_in_random_area))\n",
    "        nevts_ctrl.append(np.asarray(tmp).mean())\n",
    "\n",
    "    ## summarize the sampling\n",
    "    area_df=pd.DataFrame()\n",
    "    area_df['area']=area\n",
    "    area_df['nevts']=nevts\n",
    "    area_df['nevts_ctrl']=nevts_ctrl\n",
    "    area_df['density']=area_df.nevts/area_df.area\n",
    "    print(ss.ranksums(area_df.nevts,area_df.nevts_ctrl))\n",
    "    area_df.to_csv(id+\"EVT_density.tsv\",sep=\"\\t\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c1a32-66c5-4033-ae9a-7f6adefdb61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
